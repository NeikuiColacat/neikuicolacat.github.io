📚 多模态研究阅读列表（2018–2025）

Spatial Information Guided Convolution for Real-Time RGBD Semantic Segmentation TIP 2021 → RGB-D 语义分割

JCS: Joint Classification and Segmentation for COVID-19 Diagnosis TIP 2021 → 医学影像多模态（分类+分割）

Temporal Modulation Network for Controllable Space-Time Video Super-Resolution CVPR 2021 → 视频超分辨率（视觉+时间序列）

过渡阶段：跨模态知识迁移与生成（2022–2023）
L2G: Local-to-Global Knowledge Transfer for Weakly Supervised Semantic Segmentation CVPR 2022 → 跨层次/跨模态知识迁移

Fmnet: Frequency-aware Modulation Network for SDR-to-HDR Translation ACM MM 2022 → 图像模态转换（SDR→HDR）

Masked Autoencoders are Efficient Class Incremental Learners ICCV 2023 → 自监督预训练迁移到增量学习

SLAN: Self-Locator Aided Network for Vision-language Understanding ICCV 2023 → 初步进入视觉-语言理解

Multi-Space Neural Radiance Fields CVPR 2023 → NeRF 表征（视觉+3D）

Masked Diffusion Transformer is a Strong Image Synthesizer ICCV 2023 → 扩散模型生成（跨模态生成）

前沿阶段：视觉-语言对齐与3D生成（2024）
Cascade-CLIP: Cascaded Vision-Language Embeddings Alignment for Zero-Shot Semantic Segmentation ICML 2024 → 视觉-语言对齐

Dformer: Rethinking RGBD Representation Learning for Semantic Segmentation ICLR 2024 → RGB-D 表征学习

TeMO: Text-driven 3D Stylization for Multi-Object Meshes CVPR 2024 → 文本驱动的 3D 风格化（文本+视觉+3D）

StoryDiffusion: Consistent Self-Attention for Long-Range Image and Video Generation NeurIPS 2024 → 长序列图像/视频生成

MaskDiffusion: Boosting Text-to-Image Consistency with Conditional Mask IJCV 2024 → 文本-图像一致性增强

Sardet-100k: SAR Object Detection Benchmark NeurIPS 2024 → 遥感多模态检测（SAR+视觉）

全面开花阶段：多模态大模型（2025）
Unbiased Region-Language Alignment for Open-Vocabulary Dense Prediction ICCV 2025 → 视觉-语言对齐

Re-Aligning Language to Visual Objects with an Agentic Workflow ICLR 2025 → 智能体式视觉-语言对齐

TempSamp-R1: Effective Temporal Sampling for Video LLMs NeurIPS 2025 → 视频大模型（Video LLM）

LLaVA-Scissor / Llava-octopus arXiv 2025 → 视频理解中的多模态 LLM

TAR3D: Creating High-Quality 3D Assets via Next-Part Prediction ICCV 2025 → 3D 多模态生成

AR-1-to-3: Single Image to Consistent 3D Object Generation ICCV 2025 → 单图像到 3D 对象生成

OmniSegmentor: A Flexible Multi-Modal Learning Framework for Semantic Segmentation NeurIPS 2025 → 通用多模态分割框架

Docopilot: Document-Level Multimodal Understanding CVPR 2025 → 文档级多模态理解

MedSeg-R / McaNet 2025 → 医学影像多模态分割

Sm3det: Multi-modal Remote Sensing Object Detection arXiv 2024 → 遥感多模态检测

🎯 阅读建议
第一阶段（2018–2019）：先读 RGB-D 和视频显著性检测的工作，理解多模态感知的起点。

第二阶段（2020–2021）：扩展到视频修复/超分辨率和医学影像，体会跨任务多模态。

第三阶段（2022–2023）：重点看 L2G、SLAN、NeRF、Diffusion，这是进入生成式和视觉-语言的关键。

第四阶段（2024）：阅读 Cascade-CLIP、TeMO、StoryDiffusion，理解视觉-语言对齐和 3D/长序列生成。

第五阶段（2025）：最后看 Video LLMs、OmniSegmentor、Docopilot、TAR3D，这是团队最新的多模态大模型成果。
